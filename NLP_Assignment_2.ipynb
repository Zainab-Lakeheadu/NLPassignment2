{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Assignment_2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLcgd-DlU-K5",
        "colab_type": "text"
      },
      "source": [
        "Importing the libraries for pre-processing the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee1b-jzz8AfZ",
        "colab_type": "code",
        "outputId": "32396a08-7fbe-4aae-950a-09b50e0baa71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemma=WordNetLemmatizer()\n",
        "from string import punctuation\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvwU7RQ1VEtt",
        "colab_type": "text"
      },
      "source": [
        "loading and reading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "130TPHYF8Ofh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/cacoderquan/Sentiment-Analysis-on-the-Rotten-Tomatoes-movie-review-dataset/master/train.tsv\"\n",
        "df = pd.read_csv(url, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7n62LWV8TMp",
        "colab_type": "code",
        "outputId": "4cfbfdea-a21a-4b5b-8196-0d5c8644eeca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>of escapades demonstrating the adage that what...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades demonstrating the adage that what is...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>escapades</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating the adage that what is good for ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "5         6  ...          2\n",
              "6         7  ...          2\n",
              "7         8  ...          2\n",
              "8         9  ...          2\n",
              "9        10  ...          2\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yf5G2l1VQ0J",
        "colab_type": "text"
      },
      "source": [
        "method for pre-processing the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgG_XCpA8bvS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(each_col):\n",
        "    documents=[]\n",
        "    for i in range(0,len(each_col)):\n",
        "        document=str(each_col[i])\n",
        "        document=re.sub('[^a-zA-Z]',' ',document)\n",
        "        document=[lemma.lemmatize(w) for w in word_tokenize(str(document).lower())]\n",
        "        document=' '.join(document)\n",
        "        documents.append(document)\n",
        "    return documents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrVQVKmVVVts",
        "colab_type": "text"
      },
      "source": [
        "Created another column for adding the pre-processed text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3gtKyci8gVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['pre_processed']=clean_text(df.Phrase.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLTJu3u78nFo",
        "colab_type": "code",
        "outputId": "1ba0efb7-f827-44e8-d592-fdcff2a15047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>pre_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "      <td>a series of escapade demonstrating the adage t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "      <td>a series of escapade demonstrating the adage t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "      <td>a series</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "      <td>series</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...                                      pre_processed\n",
              "0         1  ...  a series of escapade demonstrating the adage t...\n",
              "1         2  ...  a series of escapade demonstrating the adage t...\n",
              "2         3  ...                                           a series\n",
              "3         4  ...                                                  a\n",
              "4         5  ...                                             series\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_UQ9v467etY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(color_codes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uTnxEmdVj7G",
        "colab_type": "text"
      },
      "source": [
        "Analyzing the distribution of classes and that the dataset is imbalanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgNGkAm37gV_",
        "colab_type": "code",
        "outputId": "68609a09-8212-4c16-e1ce-d1570bc2fab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "dist = df.groupby([\"Sentiment\"]).size()\n",
        "dist = dist / dist.sum()\n",
        "fig, ax = plt.subplots()\n",
        "tips = sns.load_dataset(\"tips\")\n",
        "sns.barplot(dist.keys(), dist.values, color = \"blue\");\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEMCAYAAADOLq1xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYPEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riNKokD7Vzf_",
        "colab_type": "text"
      },
      "source": [
        "Initializing the X (pre-processed text) and Y (Sentiment as the target variable) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5PlPPTV9hY5",
        "colab_type": "code",
        "outputId": "3cf494ad-3f26-40d6-de17-b1cbdec88d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "X = df['pre_processed']\n",
        "Y = (df['Sentiment'].values)\n",
        "print(Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[1 2 2 ... 3 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3kU1et0V9rt",
        "colab_type": "text"
      },
      "source": [
        "Splitting the dataset in the ratio 0f 70:30 with random state of 2003"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onh40K9m907a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=2003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llutspQJWFj9",
        "colab_type": "text"
      },
      "source": [
        "Converting the Y_test into one-hot label "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyMSJNu3FI1W",
        "colab_type": "code",
        "outputId": "faeb6b98-3fdc-42a8-d377-db91297407ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "Y_test = to_categorical(Y_test)\n",
        "print(Y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPG2oEIEHBG7",
        "colab_type": "code",
        "outputId": "e8b68617-66b1-4ee7-bd1d-c533aadf5ff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(109242,) (109242,)\n",
            "(46818,) (46818, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i-8AMhCWRWj",
        "colab_type": "text"
      },
      "source": [
        "using the X_train and Y_train for resampling the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ6m-l_0CecA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = X_train.tolist() \n",
        "l = []\n",
        "for i in range(len(x_train)):\n",
        "        join = (x_train[i],Y_train[i])\n",
        "        l.append(join)\n",
        "D = pd.DataFrame(l,columns=['pre_processed', 'Sentiment'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zijVoSMADeHC",
        "colab_type": "code",
        "outputId": "b18f1f7c-5a55-47a8-cd82-923dcc8d83d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "D.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pre_processed</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>their age</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gorgeous epic</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fan of the gross out comedy</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the filmmaker ascends literally to the olympus...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>twisting mystery</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       pre_processed  Sentiment\n",
              "0                                          their age          2\n",
              "1                                      gorgeous epic          4\n",
              "2                        fan of the gross out comedy          2\n",
              "3  the filmmaker ascends literally to the olympus...          4\n",
              "4                                   twisting mystery          2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt4glCdMWaP0",
        "colab_type": "text"
      },
      "source": [
        "Assigning the texts of each classes into each objects and then resampling the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHW68sqBDmDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample\n",
        "category_0 = D[D['Sentiment']==0]\n",
        "category_1 = D[D['Sentiment']==1]\n",
        "category_2 = D[D['Sentiment']==2]\n",
        "category_3 = D[D['Sentiment']==3]\n",
        "category_4 = D[D['Sentiment']==4]\n",
        "\n",
        "category_0_sample = resample(category_0,replace=True,n_samples=75000,random_state=2003)\n",
        "category_1_sample = resample(category_1,replace=True,n_samples=75000,random_state=2003)\n",
        "category_2_sample = resample(category_2,replace=True,n_samples=75000,random_state=2003)\n",
        "category_3_sample = resample(category_3,replace=True,n_samples=75000,random_state=2003)\n",
        "category_4_sample = resample(category_4,replace=True,n_samples=75000,random_state=2003)\n",
        "df_resampled = pd.concat([category_0_sample, category_1_sample,category_2_sample,category_3_sample,category_4_sample])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzK71bmvWvOH",
        "colab_type": "text"
      },
      "source": [
        "Assigning the new resampled texts and its corresponding classes to X_train and Y_train respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTfWt0CwDhdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df_resampled['pre_processed']\n",
        "Y_train= to_categorical(df_resampled['Sentiment'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5zSNTh4CuDd",
        "colab_type": "code",
        "outputId": "e627865a-29e6-4615-ae9f-f0b9617f6fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(375000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMINC8A2CUNS",
        "colab_type": "code",
        "outputId": "fc32fb8b-80cf-4cc7-9cee-14ae1013eb3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(Y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(375000, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqN_QIZmihNG",
        "colab_type": "text"
      },
      "source": [
        "Importing libraries for padding and sequencing the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nns8XD1wHESw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import sequence,text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7gPb6HOjR-7",
        "colab_type": "text"
      },
      "source": [
        "Finding the maximum number of unique words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7bNaSYEHHi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words=' '.join(X_train)\n",
        "words=word_tokenize(words)\n",
        "dist=FreqDist(words)\n",
        "num_word=len(dist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7lRphegjdJy",
        "colab_type": "text"
      },
      "source": [
        "Finding the maximum length of words for each document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lErGOqWkJIE_",
        "colab_type": "code",
        "outputId": "a896326e-7784-4258-9223-06bb6c5054af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc_len=[]\n",
        "for text in X_train:\n",
        "    word=word_tokenize(text)\n",
        "    l=len(word)\n",
        "    doc_len.append(l)    \n",
        "max_doc_len=np.max(doc_len)\n",
        "max_doc_len"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gOCqNFOjpcz",
        "colab_type": "text"
      },
      "source": [
        "Initializing the number of epochs, batch size, maximum features and maximum words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfTyttbAJM7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = num_word\n",
        "max_words = max_doc_len\n",
        "batch_size = 256\n",
        "epochs = 40\n",
        "num_classes=5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2rC_gccj-bR",
        "colab_type": "text"
      },
      "source": [
        "tokenizing the text with keras tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2x7RIK6KE9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si3tExo6kPB1",
        "colab_type": "text"
      },
      "source": [
        "Initializing the padded sequence words in X_train and X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "223i51tLK0me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AucPX0Otkfh7",
        "colab_type": "text"
      },
      "source": [
        "Importing the libraries for creating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEXkCWVbK5r6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense,Dropout,Embedding,Conv1D,Flatten,MaxPooling1D,SpatialDropout1D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adamax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "estISdPcK9Ko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense, Embedding, Flatten\n",
        "from keras.layers import SpatialDropout1D\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LeakyReLU, PReLU\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiK7s4XPkjoZ",
        "colab_type": "text"
      },
      "source": [
        "Creating the model with embedding layer, dropout layer for reducing overfitting, convolutional layer, activation layer and max_pooling layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwLQCPZoLACo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "# Input / Embdedding\n",
        "model.add(Embedding(max_features, 100, input_length=max_words))\n",
        "# CNN\n",
        "model.add(SpatialDropout1D(0.5))\n",
        "model.add(Conv1D(32, kernel_size=3, padding='same'))\n",
        "model.add(LeakyReLU(alpha=0.05))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(128, kernel_size=3, padding='same'))\n",
        "model.add(PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=None))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(128, kernel_size=3, padding='same'))\n",
        "model.add(PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=None))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6tXda6xk57x",
        "colab_type": "text"
      },
      "source": [
        "Importing metrics for calculating precision and recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yNqOqHWLD0X",
        "colab_type": "code",
        "outputId": "68d51ae6-81dc-4fec-fd8b-52fb02feed46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install keras-metrics\n",
        "import keras_metrics"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-metrics in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras-metrics) (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.18.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ9tz429lAWd",
        "colab_type": "text"
      },
      "source": [
        "Compiling and fitting the layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX0AVdgJLO6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=['accuracy',keras_metrics.precision(), keras_metrics.recall()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V39G3g1FLSva",
        "colab_type": "code",
        "outputId": "4851ebd1-3390-45d0-bf94-4e9e8b98825a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=epochs, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 375000 samples, validate on 46818 samples\n",
            "Epoch 1/40\n",
            "375000/375000 [==============================] - 12s 32us/step - loss: 1.0483 - acc: 0.5552 - precision: 0.7535 - recall: 0.5759 - val_loss: 0.9653 - val_acc: 0.5919 - val_precision: 0.4519 - val_recall: 0.4909\n",
            "Epoch 2/40\n",
            "375000/375000 [==============================] - 12s 32us/step - loss: 0.7818 - acc: 0.6777 - precision: 0.7894 - recall: 0.7935 - val_loss: 0.9661 - val_acc: 0.5902 - val_precision: 0.3879 - val_recall: 0.6160\n",
            "Epoch 3/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.6910 - acc: 0.7197 - precision: 0.8144 - recall: 0.8532 - val_loss: 0.9755 - val_acc: 0.5956 - val_precision: 0.4095 - val_recall: 0.5751\n",
            "Epoch 4/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.6292 - acc: 0.7481 - precision: 0.8313 - recall: 0.8824 - val_loss: 0.9923 - val_acc: 0.6018 - val_precision: 0.3766 - val_recall: 0.6406\n",
            "Epoch 5/40\n",
            "375000/375000 [==============================] - 12s 32us/step - loss: 0.5828 - acc: 0.7692 - precision: 0.8474 - recall: 0.9031 - val_loss: 1.0348 - val_acc: 0.5885 - val_precision: 0.3978 - val_recall: 0.6104\n",
            "Epoch 6/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.5487 - acc: 0.7848 - precision: 0.8583 - recall: 0.9140 - val_loss: 1.0930 - val_acc: 0.5938 - val_precision: 0.3796 - val_recall: 0.6192\n",
            "Epoch 7/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.5192 - acc: 0.7972 - precision: 0.8659 - recall: 0.9231 - val_loss: 1.0868 - val_acc: 0.5900 - val_precision: 0.3694 - val_recall: 0.6206\n",
            "Epoch 8/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.4933 - acc: 0.8088 - precision: 0.8758 - recall: 0.9302 - val_loss: 1.1176 - val_acc: 0.5946 - val_precision: 0.4027 - val_recall: 0.5490\n",
            "Epoch 9/40\n",
            "375000/375000 [==============================] - 12s 32us/step - loss: 0.4713 - acc: 0.8185 - precision: 0.8814 - recall: 0.9356 - val_loss: 1.1221 - val_acc: 0.6025 - val_precision: 0.3855 - val_recall: 0.5807\n",
            "Epoch 10/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.4521 - acc: 0.8264 - precision: 0.8880 - recall: 0.9393 - val_loss: 1.1700 - val_acc: 0.5943 - val_precision: 0.3908 - val_recall: 0.5472\n",
            "Epoch 11/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.4351 - acc: 0.8333 - precision: 0.8927 - recall: 0.9428 - val_loss: 1.1709 - val_acc: 0.5987 - val_precision: 0.3772 - val_recall: 0.5807\n",
            "Epoch 12/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.4192 - acc: 0.8397 - precision: 0.8980 - recall: 0.9461 - val_loss: 1.2024 - val_acc: 0.5996 - val_precision: 0.4053 - val_recall: 0.5314\n",
            "Epoch 13/40\n",
            "375000/375000 [==============================] - 12s 32us/step - loss: 0.4060 - acc: 0.8452 - precision: 0.9016 - recall: 0.9479 - val_loss: 1.1878 - val_acc: 0.6179 - val_precision: 0.4046 - val_recall: 0.5165\n",
            "Epoch 14/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.3934 - acc: 0.8509 - precision: 0.9058 - recall: 0.9514 - val_loss: 1.2477 - val_acc: 0.6074 - val_precision: 0.3908 - val_recall: 0.5662\n",
            "Epoch 15/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.3819 - acc: 0.8552 - precision: 0.9100 - recall: 0.9536 - val_loss: 1.2836 - val_acc: 0.6027 - val_precision: 0.3890 - val_recall: 0.5542\n",
            "Epoch 16/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.3701 - acc: 0.8608 - precision: 0.9134 - recall: 0.9552 - val_loss: 1.3057 - val_acc: 0.6001 - val_precision: 0.3812 - val_recall: 0.5625\n",
            "Epoch 17/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.3619 - acc: 0.8638 - precision: 0.9163 - recall: 0.9575 - val_loss: 1.3462 - val_acc: 0.6031 - val_precision: 0.3906 - val_recall: 0.5421\n",
            "Epoch 18/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.3514 - acc: 0.8681 - precision: 0.9184 - recall: 0.9581 - val_loss: 1.3476 - val_acc: 0.6056 - val_precision: 0.3911 - val_recall: 0.5393\n",
            "Epoch 19/40\n",
            "375000/375000 [==============================] - 12s 32us/step - loss: 0.3438 - acc: 0.8710 - precision: 0.9207 - recall: 0.9593 - val_loss: 1.3438 - val_acc: 0.6094 - val_precision: 0.3988 - val_recall: 0.5495\n",
            "Epoch 20/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.3353 - acc: 0.8744 - precision: 0.9233 - recall: 0.9608 - val_loss: 1.4176 - val_acc: 0.5943 - val_precision: 0.3812 - val_recall: 0.5490\n",
            "Epoch 21/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.3284 - acc: 0.8776 - precision: 0.9257 - recall: 0.9609 - val_loss: 1.4208 - val_acc: 0.6109 - val_precision: 0.4122 - val_recall: 0.4881\n",
            "Epoch 22/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.3223 - acc: 0.8798 - precision: 0.9271 - recall: 0.9620 - val_loss: 1.4298 - val_acc: 0.5993 - val_precision: 0.4130 - val_recall: 0.4844\n",
            "Epoch 23/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.3146 - acc: 0.8829 - precision: 0.9288 - recall: 0.9629 - val_loss: 1.4456 - val_acc: 0.6040 - val_precision: 0.3955 - val_recall: 0.5281\n",
            "Epoch 24/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.3085 - acc: 0.8860 - precision: 0.9316 - recall: 0.9649 - val_loss: 1.4385 - val_acc: 0.6050 - val_precision: 0.3983 - val_recall: 0.5016\n",
            "Epoch 25/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.3022 - acc: 0.8876 - precision: 0.9320 - recall: 0.9644 - val_loss: 1.4624 - val_acc: 0.6017 - val_precision: 0.3897 - val_recall: 0.5142\n",
            "Epoch 26/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.2975 - acc: 0.8897 - precision: 0.9339 - recall: 0.9652 - val_loss: 1.5047 - val_acc: 0.5989 - val_precision: 0.3951 - val_recall: 0.5184\n",
            "Epoch 27/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.2924 - acc: 0.8919 - precision: 0.9342 - recall: 0.9658 - val_loss: 1.5461 - val_acc: 0.5987 - val_precision: 0.4065 - val_recall: 0.4840\n",
            "Epoch 28/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.2874 - acc: 0.8939 - precision: 0.9365 - recall: 0.9669 - val_loss: 1.5210 - val_acc: 0.6013 - val_precision: 0.3910 - val_recall: 0.5114\n",
            "Epoch 29/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.2825 - acc: 0.8956 - precision: 0.9363 - recall: 0.9665 - val_loss: 1.5731 - val_acc: 0.5952 - val_precision: 0.3877 - val_recall: 0.5202\n",
            "Epoch 30/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.2784 - acc: 0.8974 - precision: 0.9384 - recall: 0.9677 - val_loss: 1.5682 - val_acc: 0.6067 - val_precision: 0.4202 - val_recall: 0.4747\n",
            "Epoch 31/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.2731 - acc: 0.8993 - precision: 0.9404 - recall: 0.9680 - val_loss: 1.5761 - val_acc: 0.6052 - val_precision: 0.4048 - val_recall: 0.4933\n",
            "Epoch 32/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.2709 - acc: 0.9000 - precision: 0.9400 - recall: 0.9678 - val_loss: 1.6134 - val_acc: 0.6008 - val_precision: 0.3822 - val_recall: 0.5416\n",
            "Epoch 33/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.2666 - acc: 0.9019 - precision: 0.9407 - recall: 0.9692 - val_loss: 1.6086 - val_acc: 0.6010 - val_precision: 0.4049 - val_recall: 0.4998\n",
            "Epoch 34/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.2640 - acc: 0.9030 - precision: 0.9415 - recall: 0.9690 - val_loss: 1.6135 - val_acc: 0.6018 - val_precision: 0.4016 - val_recall: 0.4886\n",
            "Epoch 35/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.2607 - acc: 0.9039 - precision: 0.9421 - recall: 0.9697 - val_loss: 1.6072 - val_acc: 0.6064 - val_precision: 0.3968 - val_recall: 0.4854\n",
            "Epoch 36/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.2570 - acc: 0.9060 - precision: 0.9433 - recall: 0.9701 - val_loss: 1.6155 - val_acc: 0.6072 - val_precision: 0.4044 - val_recall: 0.4821\n",
            "Epoch 37/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.2541 - acc: 0.9072 - precision: 0.9441 - recall: 0.9706 - val_loss: 1.6707 - val_acc: 0.6019 - val_precision: 0.4219 - val_recall: 0.4598\n",
            "Epoch 38/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.2510 - acc: 0.9076 - precision: 0.9436 - recall: 0.9707 - val_loss: 1.6374 - val_acc: 0.5938 - val_precision: 0.3859 - val_recall: 0.5151\n",
            "Epoch 39/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.2488 - acc: 0.9087 - precision: 0.9449 - recall: 0.9707 - val_loss: 1.7075 - val_acc: 0.5992 - val_precision: 0.4152 - val_recall: 0.4635\n",
            "Epoch 40/40\n",
            "375000/375000 [==============================] - 12s 31us/step - loss: 0.2472 - acc: 0.9094 - precision: 0.9445 - recall: 0.9710 - val_loss: 1.6099 - val_acc: 0.6053 - val_precision: 0.3922 - val_recall: 0.4840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f968004aa90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVDq4GsYlEhr",
        "colab_type": "text"
      },
      "source": [
        "Saving and loading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NareavpFXOxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('1110186_1dconv_reg.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx7thEbpXTcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('1110186_1dconv_reg.h5',{'binary_precision':keras_metrics.binary_precision(), 'binary_recall':keras_metrics.binary_recall()})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjlqnReXlIq7",
        "colab_type": "text"
      },
      "source": [
        "Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkZrN-pGVJer",
        "colab_type": "code",
        "outputId": "c198d9ba-2762-4875-c203-a2aa8e057d91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "val_loss, val_acc, val_prec, val_recall  = model.evaluate(X_test, Y_test, batch_size=256)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46818/46818 [==============================] - 1s 13us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWGH5MkalS8e",
        "colab_type": "text"
      },
      "source": [
        "Calculating accuracy, precision and recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ldbsi4fyVllC",
        "colab_type": "code",
        "outputId": "90280c98-6f2e-438a-b634-d3807a58665e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(' accuracy', val_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " accuracy 0.6053227392421986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVLDrg_bVU51",
        "colab_type": "code",
        "outputId": "deafa907-6ab5-4c5e-fdf4-2a3f61f98f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(' val_prec', val_prec)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " val_prec 0.39223813110805433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kyWV3wYVr2p",
        "colab_type": "code",
        "outputId": "0b38953c-89f6-4d3f-ca0d-6150168fcfed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(' val_recall', val_recall)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " val_recall 0.48396094837359555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtbuoX2ylN_6",
        "colab_type": "text"
      },
      "source": [
        "Calculating the F1 score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7GW0kSBVcD4",
        "colab_type": "code",
        "outputId": "b150753d-f3d7-4ade-a0ac-276aaf337fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f1_score = 2 * ((val_prec*val_recall)/(val_prec+val_recall))\n",
        "print(' f1_score', f1_score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " f1_score 0.43329864722442046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6kVxsMtey_1",
        "colab_type": "code",
        "outputId": "fa5446d8-18de-42a3-896b-1777b9fc4385",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(' val_loss', val_loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " val_loss 1.6099175378388049\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}